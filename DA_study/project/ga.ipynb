{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection,preprocessing,metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "import re\n",
    "from plotly import tools\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "import ast # Abstract Syntax Trees : The ast module helps Python applications to process trees of the Python abstract syntax grammar.\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import gc   # Garbage Collector : gc exposes the underlying memory management mechanism of Python\n",
    "gc.enable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(data):\n",
    "  data['date'] = pd.to_datetime(data['date'], format='%Y%m%d')\n",
    "  data['year'] = data['date'].dt.year\n",
    "  data['month'] = data['date'].dt.month\n",
    "  data['week'] = data['date'].dt.week\n",
    "  data['weekday'] = data['date'].dt.weekday\n",
    "\n",
    "  data['date'] = data['date'].apply(lambda x: dt.date(x.year, x.month, x.day))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_feature(data):\n",
    "  month_visit_count = data.groupby(['fullVisitorId'])['month'].agg('count').reset_index()\n",
    "  week_visit_count = data.groupby(['fullVisitorId'])['week'].agg('count').reset_index()\n",
    "  weekdaily_visit_count = data.groupby(['fullVisitorId','year','week'])['weekday'].agg('count').reset_index()\n",
    "  weekdaily_visit_count = weekdaily_visit_count.groupby(['fullVisitorId'])['weekday'].agg('mean').reset_index()\n",
    "\n",
    "  month_visit_count.rename(columns={'month':'monthly_visit'},inplace=True)\n",
    "  week_visit_count.rename(columns={'week':'weekly_visit'},inplace=True)\n",
    "  weekdaily_visit_count.rename(columns={'weekday':'weekdaily_visit'},inplace=True)\n",
    "\n",
    "  data = data.merge(month_visit_count,on='fullVisitorId',how='left')\n",
    "  data = data.merge(week_visit_count,on='fullVisitorId',how='left')\n",
    "  data = data.merge(weekdaily_visit_count,on='fullVisitorId',how='left')\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retention_rate(data):\n",
    "  total_visit_date = data.groupby(['fullVisitorId','date'])['weekday'].agg('count').reset_index()\n",
    "  first_visit_date = total_visit_date.groupby('fullVisitorId')['date'].min().reset_index()\n",
    "  total_visit_date.drop('weekday',axis=1,inplace=True)\n",
    "\n",
    "  total_visit_date_2 = pd.concat([total_visit_date, first_visit_date]).drop_duplicates(keep=False)\n",
    "\n",
    "  second_visit_date = total_visit_date_2.groupby('fullVisitorId')['date'].min().reset_index()\n",
    "  last_visit_date = total_visit_date_2.groupby('fullVisitorId')['date'].max().reset_index()\n",
    "\n",
    "  first_visit_date.rename(columns={'date':'date_first_visit'},inplace=True)\n",
    "  second_visit_date.rename(columns={'date':'date_second_visit'},inplace=True)\n",
    "  last_visit_date.rename(columns={'date':'date_last_visit'},inplace=True)\n",
    "\n",
    "  visit_date_merged = first_visit_date.merge(second_visit_date,on='fullVisitorId',how='left')\n",
    "  visit_date_merged = visit_date_merged.merge(last_visit_date,on='fullVisitorId',how='left')\n",
    "\n",
    "  visit_date_merged['revisit_dur_time'] = (visit_date_merged['date_second_visit'] - visit_date_merged['date_first_visit']).dt.days\n",
    "  visit_date_merged['total_life_time'] = (visit_date_merged['date_last_visit'] - visit_date_merged['date_first_visit']).dt.days\n",
    "\n",
    "  #stickness\n",
    "  agg_total_visit_count = total_visit_date.groupby('fullVisitorId')['date'].agg('count').reset_index()\n",
    "  agg_total_visit_count.rename(columns={'date':'agg_total_visit_count'},inplace=True)\n",
    "  agg_total_visit_count['agg_total_visit_count'] = agg_total_visit_count['agg_total_visit_count'] - 1\n",
    "  agg_total_visit_count.value_counts()\n",
    "  visit_date_merged = visit_date_merged.merge(agg_total_visit_count,on='fullVisitorId',how='left')\n",
    "  visit_date_merged['stickness'] = visit_date_merged['agg_total_visit_count']/visit_date_merged['total_life_time']\n",
    "\n",
    "  #drop datetype\n",
    "  visit_date_merged.drop(['date_first_visit','date_second_visit','date_last_visit'],axis=1,inplace=True)\n",
    "\n",
    "  #merge to train df\n",
    "  data = data.merge(visit_date_merged,on='fullVisitorId',how='left')\n",
    "\n",
    "  ##memory clear\n",
    "  del total_visit_date\n",
    "  del total_visit_date_2\n",
    "  gc.collect()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(data,numerator,denumerator):\n",
    "  data[numerator].value_counts()\n",
    "  entropy_df = data[['fullVisitorId',denumerator,numerator]]\\\n",
    "  .groupby(['fullVisitorId'])\\\n",
    "  .agg({numerator:'count',denumerator:'sum'}).reset_index()\n",
    "\n",
    "  entropy_df[denumerator].value_counts(dropna=False)\n",
    "  entropy_df[denumerator] = entropy_df[denumerator].astype('float')\n",
    "\n",
    "  entropy_df['Div'] = entropy_df[numerator]/entropy_df[denumerator]\n",
    "  with np.errstate(divide='ignore'):\n",
    "      entropy_df['Ent_Upc'] = np.where(entropy_df['Div']==0, 0, entropy_df['Div'] * np.log2(entropy_df['Div']) * -1)\n",
    "  \n",
    "  entropy_df = entropy_df[['fullVisitorId','Ent_Upc']]\n",
    "  entropy_df['Ent_Upc'] = np.abs(entropy_df['Ent_Upc'])\n",
    "  entropy_df.rename(columns={'Ent_Upc':f'{numerator}_Ent'},inplace=True)\n",
    "\n",
    "  return entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_list = [\n",
    "'hits_hitNumber',\n",
    "'hits_hour',\n",
    "'totals_timeOnSite',\n",
    "'totals_hits',\n",
    "'totals_sessionQualityDim',\n",
    "'totals_transactions',\n",
    "'totals_pageviews',\n",
    "'hits_minute',\n",
    "'visitNumber',\n",
    "'totals_bounces',\n",
    "'hits_time',\n",
    "'hits_latencyTracking.redirectionTime',\n",
    "'hour',\n",
    "'month',\n",
    "'weekday',\n",
    "'year',\n",
    "'monthly_visit',\n",
    "'weekly_visit',\n",
    "'weekdaily_visit',\n",
    "'revisit_dur_time',\n",
    "'total_life_time',\n",
    "'agg_total_visit_count',\n",
    "'stickness',\n",
    "'hits_contentGroup.contentGroup2_Ent',\n",
    "'trafficSource_adwordsClickInfo.gclId_Ent',\n",
    "'week',\n",
    "'hits_latencyTracking.pageLoadTime',\n",
    "'hits_latencyTracking.pageDownloadTime',\n",
    "'hits_latencyTracking.domainLookupTime',\n",
    "'hits_latencyTracking.domContentLoadedTime',\n",
    "'hits_latencyTracking.serverResponseTime',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = [\n",
    "'hits_social.socialInteractionNetworkAction','hits_experiment','hits_publisher_infos',\n",
    "'hits_page.pageTitle',\n",
    "'hits_page.pagePath',\n",
    "'hits_page.pagePathLevel1',\n",
    "'hits_page.pagePathLevel3',\n",
    "'hits_page.pagePathLevel2',\n",
    "'hits_page.pagePathLevel4',\n",
    "'hits_appInfo.landingScreenName',\n",
    "'hits_eventInfo.eventLabel',\n",
    "'trafficSource_keyword',\n",
    "'hits_customDimensions',\n",
    "'hits_customVariables',\n",
    "'hits_customMetrics',\n",
    "'trafficSource_adwordsClickInfo.gclId',\n",
    "'hits_latencyTracking.speedMetricsSample'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df, col, leave): # fn to aggregate all categories in df[col] except for cols in leave\n",
    "    df[col] = df[col].astype('str')\n",
    "    include = df[col].unique()  # array of all unique categories\n",
    "    include = list(include)\n",
    "    include = set(include).difference(set(leave))  # set: take out 'leave' from include\n",
    "    include = list(include)\n",
    "    df.loc[df[col].isin(include), col] = \"grouped\"  # rename all cols in 'include' to 'grouped'\n",
    "    return df\n",
    "\n",
    "def aggregate_opposite(df,col,regs,group_name): # fn to aggregate all categories in df[col] except for cols in leave\n",
    "    df[col] = df[col].astype('str')\n",
    "    include = df[col].unique()  # array of all unique categories\n",
    "    include = list(include)\n",
    "\n",
    "    for k in range(len(group_name)):\n",
    "      group_target = []\n",
    "      for i in include:\n",
    "\n",
    "        if re.findall(regs[k],i):\n",
    "          group_target.append(i)\n",
    "\n",
    "      df.loc[df[col].isin(group_target), col] = group_name[k]  # rename all cols in 'include' to 'grouped'\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_nth_rev(col,nth):\n",
    "  tmp = data.groupby(col)['totals_transactionRevenue'].agg(['size',lambda x: np.count_nonzero(x),'sum','mean'])\n",
    "  tmp.columns = ['count','count of non-zero revenue','sum','mean']\n",
    "  tmp = tmp.sort_values(by='count of non-zero revenue',ascending=False)\n",
    "  tmp = tmp.head(nth).reset_index()\n",
    "  \n",
    "  return list(tmp[col])\n",
    "\n",
    "def reduce_cat(data):\n",
    "  # 카테고리 묶기 골라내기 + 제외하고 묶기\n",
    "  regs = ['^\\/$','yt','mail']\n",
    "  group_name = ['/','yt','mail']\n",
    "  data = aggregate_opposite(data, 'trafficSource_referralPath',regs,group_name)\n",
    "  data = aggregate(data,'trafficSource_referralPath',group_name)\n",
    "\n",
    "  regs = ['google','youtube','facebook']\n",
    "  group_name = ['google','youtube','facebook']\n",
    "  data = aggregate_opposite(data, 'hits_referer',regs,group_name)\n",
    "  data = aggregate(data,'hits_referer',group_name)\n",
    "\n",
    "  regs = ['store.html','signin.html','basket','vieworderdetail','ordercompleted.html','/home']\n",
    "  group_name = ['store','signin','basket','vieworder','complete','home']\n",
    "  data = aggregate_opposite(data, 'hits_appInfo.exitScreenName',regs,group_name)\n",
    "  data = aggregate(data,'hits_appInfo.exitScreenName',group_name)\n",
    "\n",
    "  regs = ['apparel','store.html','signin.html','basket','vieworderdetail','ordercompleted.html','/home']\n",
    "  group_name = ['apparel','store','signin','basket','vieworder','complete','home']\n",
    "  data = aggregate_opposite(data, 'hits_appInfo.screenName',regs,group_name)\n",
    "  data = aggregate(data,'hits_appInfo.screenName',group_name)\n",
    "\n",
    "\n",
    "  # 카테고리 묶기 제외하고 묶기\n",
    "  data = aggregate(data,'trafficSource_source',leave=['(direct)','google','youtube.com','facebook.com'])\n",
    "  data = aggregate(data,'trafficSource_campaign',leave=['(not set)',])\n",
    "\n",
    "  ghl = get_nth_rev('geoNetwork_city',30)\n",
    "  data = aggregate(data,'geoNetwork_city',leave=ghl)\n",
    "\n",
    "  data['trafficSource_adContent'].fillna('isnull',inplace=True)\n",
    "  data = aggregate(data,'trafficSource_adContent',leave=['isnull'])\n",
    "\n",
    "  ghl = get_nth_rev('geoNetwork_country',30)\n",
    "  data = aggregate(data,'geoNetwork_country',leave=ghl)\n",
    "\n",
    "  ghl = get_nth_rev('geoNetwork_metro',15)\n",
    "  data = aggregate(data,'geoNetwork_metro',leave=ghl)\n",
    "\n",
    "  ghl = get_nth_rev('geoNetwork_region',20)\n",
    "  data = aggregate(data,'geoNetwork_region',leave=ghl)\n",
    "\n",
    "  ghl = get_nth_rev('device_browser',5)\n",
    "  data = aggregate(data,'device_browser',leave=ghl)\n",
    "\n",
    "  ghl = get_nth_rev('geoNetwork_networkDomain',10)\n",
    "  data = aggregate(data,'geoNetwork_networkDomain',leave=ghl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_vars = ['device', 'geoNetwork', 'totals', 'trafficSource', 'hits', 'customDimensions']\n",
    "\n",
    "final_vars = ['channelGrouping','customDimensions_index','customDimensions_value','date',\n",
    "'device_browser','device_deviceCategory','device_isMobile','device_operatingSystem',\n",
    "'fullVisitorId','geoNetwork_city','geoNetwork_continent','geoNetwork_country',\n",
    "'geoNetwork_metro','geoNetwork_networkDomain','geoNetwork_region','geoNetwork_subContinent',\n",
    "'hits_appInfo.exitScreenName','hits_appInfo.landingScreenName','hits_appInfo.screenDepth',\n",
    "'hits_appInfo.screenName','hits_contentGroup.contentGroup1','hits_contentGroup.contentGroup2',\n",
    "'hits_contentGroup.contentGroup3','hits_contentGroup.contentGroup4','hits_contentGroup.contentGroup5',\n",
    "'hits_contentGroup.contentGroupUniqueViews1','hits_contentGroup.contentGroupUniqueViews2',\n",
    "'hits_contentGroup.contentGroupUniqueViews3','hits_contentGroup.previousContentGroup1',\n",
    "'hits_contentGroup.previousContentGroup2','hits_contentGroup.previousContentGroup3',\n",
    "'hits_contentGroup.previousContentGroup4','hits_contentGroup.previousContentGroup5',\n",
    "'hits_customDimensions','hits_customMetrics','hits_customVariables','hits_dataSource',\n",
    "'hits_eCommerceAction.action_type','hits_eCommerceAction.option','hits_eCommerceAction.step',\n",
    "'hits_eventInfo.eventAction','hits_eventInfo.eventCategory','hits_eventInfo.eventLabel',\n",
    "'hits_exceptionInfo.isFatal','hits_experiment','hits_hitNumber','hits_hour','hits_isEntrance',\n",
    "'hits_isExit','hits_isInteraction','hits_item.currencyCode','hits_item.transactionId',\n",
    "'hits_latencyTracking.domContentLoadedTime','hits_latencyTracking.domInteractiveTime',\n",
    "'hits_latencyTracking.domLatencyMetricsSample','hits_latencyTracking.domainLookupTime',\n",
    "'hits_latencyTracking.pageDownloadTime','hits_latencyTracking.pageLoadSample',\n",
    "'hits_latencyTracking.pageLoadTime','hits_latencyTracking.redirectionTime',\n",
    "'hits_latencyTracking.serverConnectionTime','hits_latencyTracking.serverResponseTime',\n",
    "'hits_latencyTracking.speedMetricsSample','hits_minute','hits_page.hostname','hits_page.pagePath',\n",
    "'hits_page.pagePathLevel1','hits_page.pagePathLevel2','hits_page.pagePathLevel3',\n",
    "'hits_page.pagePathLevel4','hits_page.pageTitle','hits_page.searchCategory','hits_page.searchKeyword',\n",
    "'hits_promotionActionInfo.promoIsClick','hits_promotionActionInfo.promoIsView','hits_publisher_infos',\n",
    "'hits_referer','hits_social.hasSocialSourceReferral','hits_social.socialInteractionNetworkAction',\n",
    "'hits_social.socialNetwork','hits_time','hits_transaction.affiliation','hits_transaction.currencyCode',\n",
    "'hits_transaction.localTransactionRevenue','hits_transaction.localTransactionShipping',\n",
    "'hits_transaction.localTransactionTax','hits_transaction.transactionId',\n",
    "'hits_transaction.transactionRevenue','hits_transaction.transactionShipping',\n",
    "'hits_transaction.transactionTax','hits_type','totals_bounces','totals_hits','totals_newVisits',\n",
    "'totals_pageviews','totals_sessionQualityDim','totals_timeOnSite','totals_totalTransactionRevenue',\n",
    "'totals_transactionRevenue','totals_transactions','trafficSource_adContent',\n",
    "'trafficSource_adwordsClickInfo.adNetworkType','trafficSource_adwordsClickInfo.gclId',\n",
    "'trafficSource_adwordsClickInfo.isVideoAd','trafficSource_adwordsClickInfo.page',\n",
    "'trafficSource_adwordsClickInfo.slot','trafficSource_campaign','trafficSource_isTrueDirect',\n",
    "'trafficSource_keyword','trafficSource_medium','trafficSource_referralPath','trafficSource_source',\n",
    "'visitId','visitNumber','visitStartTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_v/kggs6h5567n9f1tb2crdb8300000gn/T/ipykernel_10316/862038937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/My Passport/train_02_fin.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/My Passport/test_v2_0.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/test1/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;31m# expected \"IO[bytes]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "train_v2 = pd.read_pickle('/Volumes/My Passport/train_02_fin.pkl')\n",
    "test_v2 = pd.read_pickle('/Volumes/My Passport/test_v2_0.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
