{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이스라인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_device :  mps\n"
     ]
    }
   ],
   "source": [
    "is_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if is_mps else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('current_device : ',device)\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.mkdir('/Volumes/My Passport/dataset/data')\n",
    "# !unzip -qq '/Volumes/My Passport/dataset/dataset.zip' -d '/Volumes/My Passport/dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#폴더 이미 생성되어 주석처리\n",
    "original_dataset_dir = '/Volumes/My Passport/dataset/data'\n",
    "classes_list = []\n",
    "\n",
    "for i in os.listdir(original_dataset_dir):\n",
    "    if os.path.isdir(os.path.join(original_dataset_dir,i)):\n",
    "        classes_list.append(i)\n",
    "\n",
    "base_dir = '/Volumes/My Passport/dataset/splitted'\n",
    "# os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pepper,_bell___healthy\n",
      "Grape___Esca_(Black_Measles)\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Strawberry___healthy\n",
      "Grape___Black_rot\n",
      "Corn___Common_rust\n",
      "Apple___Apple_scab\n",
      "Potato___healthy\n",
      "Potato___Late_blight\n",
      "Cherry___healthy\n",
      "Tomato___Bacterial_spot\n",
      "Apple___Black_rot\n",
      "Cherry___Powdery_mildew\n",
      "Corn___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Peach___healthy\n",
      "Tomato___Early_blight\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Potato___Early_blight\n",
      "Grape___healthy\n",
      "Apple___Cedar_apple_rust\n",
      "Corn___Northern_Leaf_Blight\n",
      "Tomato___Septoria_leaf_spot\n",
      "Corn___healthy\n",
      "Strawberry___Leaf_scorch\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Late_blight\n",
      "Tomato___healthy\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Apple___healthy\n",
      "Tomato___Target_Spot\n",
      "Peach___Bacterial_spot\n"
     ]
    }
   ],
   "source": [
    "#데이터 분기할 폴더 트리 생성\n",
    "import shutil\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "# os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "# os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "# os.mkdir(test_dir)\n",
    "\n",
    "for cls in classes_list:\n",
    "    print(cls)\n",
    "    # os.mkdir(os.path.join(train_dir,cls))\n",
    "    # os.mkdir(os.path.join(validation_dir,cls))\n",
    "    # os.mkdir(os.path.join(test_dir,cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 현황 확인\n",
    "#신규 트리구조로 파일 복사\n",
    "import math\n",
    "\n",
    "for cls in classes_list:\n",
    "    if os.path.isdir(os.path.join(original_dataset_dir, cls)):\n",
    "        path = os.path.join(original_dataset_dir,cls)\n",
    "        #DS.store 파일 무시\n",
    "        fnames = sorted((f for f in os.listdir(path) if not f.startswith('.')),key=str.lower)\n",
    "        print(len(fnames))\n",
    "        train_size = math.floor(len(fnames) * 0.6)\n",
    "        validation_size = math.floor(len(fnames) * 0.2)\n",
    "        test_size = math.floor(len(fnames) * 0.2)\n",
    "        \n",
    "        train_fnames = fnames[:train_size]\n",
    "        print(\"Train size(\",cls,\") \", len(train_fnames))\n",
    "        for fname in train_fnames:\n",
    "            source = os.path.join(path,fname)\n",
    "            destination = os.path.join(os.path.join(train_dir,cls),fname)\n",
    "            shutil.copyfile(source,destination)\n",
    "        \n",
    "        validation_fnames = fnames[train_size:(train_size+validation_size)]\n",
    "        print(\"Validation size(\",cls,\") \", len(validation_fnames))\n",
    "        for fname in validation_fnames:\n",
    "            source = os.path.join(path,fname)\n",
    "            destination = os.path.join(os.path.join(validation_dir,cls),fname)\n",
    "            shutil.copyfile(source,destination)\n",
    "        \n",
    "        test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "        print(\"Test size(\",cls,\") \", len(test_fnames))\n",
    "        for fname in test_fnames:\n",
    "            source = os.path.join(path,fname)\n",
    "            destination = os.path.join(os.path.join(test_dir,cls),fname)\n",
    "            shutil.copyfile(source,destination)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsfile 삭제\n",
    "folders = [train_dir,validation_dir,test_dir]\n",
    "\n",
    "for folder in folders:\n",
    "    for cls in classes_list:\n",
    "        target = folder+'/'+cls\n",
    "        for root, dirs, files in os.walk(target):\n",
    "            for file in files:\n",
    "                if file.startswith('.'):\n",
    "                    os.remove(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#이미지 사이즈 조정 및 텐서화\n",
    "transform_base = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])\n",
    "#이미지폴더 : 폴더를 클래스화. 폴더 이름을 라벨로 지정\n",
    "train_dataset = ImageFolder(root=train_dir,transform=transform_base)\n",
    "validation_dataset = ImageFolder(root=validation_dir,transform=transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4\n",
    "                          )\n",
    "val_loader = DataLoader(validation_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64,64,3,padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4096,512)\n",
    "        self.fc2 = nn.Linear(512,33)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Net().to(device)\n",
    "optimizer = optim.Adam(model_base.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data,target = data.to(device),target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target,reduction='sum').sum()\n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct/len(test_loader.dataset)\n",
    "    return test_loss,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs=30):\n",
    "    best_acc = 0.0\n",
    "    best_model_weight = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        since = time.time()\n",
    "        train(model, train_loader,optimizer)\n",
    "        train_loss,train_acc = evaluate(model,train_loader)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_weight = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "        print('------------- epoch {} -------------'.format(epoch))\n",
    "        print('train loss:{:.4f}, Accuracy:{:.2f}%'.format(train_loss,train_acc))\n",
    "        print('val loss:{:.4f}, Accuracy:{:.2f}%'.format(val_loss,val_acc))\n",
    "        print('completed {:.0f}m {:.0f}s'.format(time_elapsed//60,time_elapsed%60))\n",
    "    \n",
    "    model.load_state_dict(best_model_weight)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론을 위해 모델을 저장할 때는 그 모델의 학습된 매개변수만 저장하면 됩니다. torch.save() 를 사용하여 모델의 state_dict 를 저장하는 것이 나중에 모델을 사용할 때 가장 유연하게 사용할 수 있는, 모델 저장 시 권장하는 방법입니다.\n",
    "\n",
    "PyTorch에서는 모델을 저장할 때 .pt 또는 .pth 확장자를 사용하는 것이 일반적인 규칙입니다.\n",
    "\n",
    "추론을 실행하기 전에 반드시 model.eval() 을 호출하여 드롭아웃 및 배치 정규화를 평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는 추론 결과가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch 1 -------------\n",
      "train loss:0.8813, Accuracy:74.68%\n",
      "val loss:0.9231, Accuracy:73.34%\n",
      "completed 2m 20s\n",
      "------------- epoch 2 -------------\n",
      "train loss:0.6885, Accuracy:77.99%\n",
      "val loss:0.7428, Accuracy:76.76%\n",
      "completed 2m 18s\n",
      "------------- epoch 3 -------------\n",
      "train loss:0.4274, Accuracy:87.40%\n",
      "val loss:0.4882, Accuracy:85.12%\n",
      "completed 2m 19s\n",
      "------------- epoch 4 -------------\n",
      "train loss:0.3710, Accuracy:88.02%\n",
      "val loss:0.4549, Accuracy:85.35%\n",
      "completed 2m 18s\n",
      "------------- epoch 5 -------------\n",
      "train loss:0.3495, Accuracy:88.63%\n",
      "val loss:0.4453, Accuracy:85.22%\n",
      "completed 2m 17s\n",
      "------------- epoch 6 -------------\n",
      "train loss:0.2308, Accuracy:93.18%\n",
      "val loss:0.3342, Accuracy:89.40%\n",
      "completed 18m 53s\n",
      "------------- epoch 7 -------------\n",
      "train loss:0.2068, Accuracy:93.84%\n",
      "val loss:0.3243, Accuracy:89.47%\n",
      "completed 10m 4s\n",
      "------------- epoch 8 -------------\n",
      "train loss:0.1604, Accuracy:95.11%\n",
      "val loss:0.2802, Accuracy:90.93%\n",
      "completed 21m 9s\n",
      "------------- epoch 9 -------------\n",
      "train loss:0.1497, Accuracy:95.57%\n",
      "val loss:0.2756, Accuracy:91.50%\n",
      "completed 2m 17s\n",
      "------------- epoch 10 -------------\n",
      "train loss:0.1373, Accuracy:95.78%\n",
      "val loss:0.2688, Accuracy:91.09%\n",
      "completed 2m 17s\n",
      "------------- epoch 11 -------------\n",
      "train loss:0.0999, Accuracy:97.07%\n",
      "val loss:0.2335, Accuracy:92.41%\n",
      "completed 2m 18s\n",
      "------------- epoch 12 -------------\n",
      "train loss:0.0970, Accuracy:97.40%\n",
      "val loss:0.2255, Accuracy:92.70%\n",
      "completed 2m 18s\n",
      "------------- epoch 13 -------------\n",
      "train loss:0.0928, Accuracy:97.17%\n",
      "val loss:0.2411, Accuracy:92.36%\n",
      "completed 2m 19s\n",
      "------------- epoch 14 -------------\n",
      "train loss:0.1116, Accuracy:96.46%\n",
      "val loss:0.2661, Accuracy:91.55%\n",
      "completed 2m 19s\n",
      "------------- epoch 15 -------------\n",
      "train loss:0.0820, Accuracy:97.47%\n",
      "val loss:0.2291, Accuracy:92.78%\n",
      "completed 2m 18s\n",
      "------------- epoch 16 -------------\n",
      "train loss:0.0696, Accuracy:98.06%\n",
      "val loss:0.2140, Accuracy:93.45%\n",
      "completed 2m 18s\n",
      "------------- epoch 17 -------------\n",
      "train loss:0.0922, Accuracy:97.31%\n",
      "val loss:0.2509, Accuracy:92.08%\n",
      "completed 2m 17s\n",
      "------------- epoch 18 -------------\n",
      "train loss:0.1026, Accuracy:96.71%\n",
      "val loss:0.2702, Accuracy:91.68%\n",
      "completed 2m 17s\n",
      "------------- epoch 19 -------------\n",
      "train loss:0.0675, Accuracy:97.86%\n",
      "val loss:0.2352, Accuracy:92.60%\n",
      "completed 2m 17s\n",
      "------------- epoch 20 -------------\n",
      "train loss:0.0594, Accuracy:98.16%\n",
      "val loss:0.2176, Accuracy:93.30%\n",
      "completed 2m 18s\n",
      "------------- epoch 21 -------------\n",
      "train loss:0.0452, Accuracy:98.94%\n",
      "val loss:0.1845, Accuracy:94.00%\n",
      "completed 2m 18s\n",
      "------------- epoch 22 -------------\n",
      "train loss:0.1037, Accuracy:96.50%\n",
      "val loss:0.2984, Accuracy:90.89%\n",
      "completed 2m 18s\n",
      "------------- epoch 23 -------------\n",
      "train loss:0.0674, Accuracy:97.67%\n",
      "val loss:0.2564, Accuracy:92.56%\n",
      "completed 2m 19s\n",
      "------------- epoch 24 -------------\n",
      "train loss:0.0541, Accuracy:98.44%\n",
      "val loss:0.2135, Accuracy:93.40%\n",
      "completed 2m 18s\n",
      "------------- epoch 25 -------------\n",
      "train loss:0.0439, Accuracy:98.67%\n",
      "val loss:0.2176, Accuracy:93.67%\n",
      "completed 2m 18s\n",
      "------------- epoch 26 -------------\n",
      "train loss:0.0417, Accuracy:98.79%\n",
      "val loss:0.2018, Accuracy:93.77%\n",
      "completed 2m 17s\n",
      "------------- epoch 27 -------------\n",
      "train loss:0.0485, Accuracy:98.51%\n",
      "val loss:0.2230, Accuracy:93.24%\n",
      "completed 2m 17s\n",
      "------------- epoch 28 -------------\n",
      "train loss:0.0441, Accuracy:98.61%\n",
      "val loss:0.2283, Accuracy:93.07%\n",
      "completed 2m 17s\n",
      "------------- epoch 29 -------------\n",
      "train loss:0.0206, Accuracy:99.60%\n",
      "val loss:0.1726, Accuracy:94.93%\n",
      "completed 2m 17s\n",
      "------------- epoch 30 -------------\n",
      "train loss:0.0345, Accuracy:99.00%\n",
      "val loss:0.1993, Accuracy:93.90%\n",
      "completed 2m 17s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base = train_baseline(model_base,train_loader,val_loader,optimizer,epochs)\n",
    "torch.save(base,'badseline.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전이학습 모델"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "data_transforms = {\n",
    "    #Compose : 전처리할때 사용됨.\n",
    "    'train' : \n",
    "        transforms.Compose([transforms.Resize([64,64]),\n",
    "        #기하학적 증강. 과적합을 방지하기 위함\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        #RGB 색상값의 평균,표준편차. 색상분포의 히스토그램을 찾아 적용하는 것.\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) ]),\n",
    "    'validation' : \n",
    "        transforms.Compose([transforms.Resize([64,64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리된 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "image_datasets = {x: ImageFolder(root=os.path.join(base_dir,x),\n",
    "                                 transform=data_transforms[x]) for x in ['train','validation']}\n",
    "dataloader = {x : DataLoader(image_datasets[x],\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=4,\n",
    "                             ) for x in ['train','validation']}\n",
    "dataset_sizes = {x : len(image_datasets[x]) for x in ['train','validation']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet50 모델 fineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nam-yeong/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nam-yeong/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/nam-yeong/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "#resnet50 모델 가져온다 (pretrained된 모델)\n",
    "resnet = models.resnet50(pretrained = True)\n",
    "#기성모델의 마지막 fully connected layer 채널 수를 우리의 입력값으로 변경해줘야함. baseline model = 33\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs,33)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#마지막 fc가 변경되었으므로 학습해야 할 필요 있음. filter는 첫번째 인자가 True인 값만 걸러내는 기능.\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad,resnet.parameters()),lr=0.001)\n",
    "\n",
    "#초기에 lr(learning-rate)를 크게주어 학습 속도를 높이고 이후 세밀조정 하는 기능\n",
    "from torch.optim import lr_scheduler\n",
    "exp_lr_shceduler = lr_scheduler.StepLR(optimizer_ft,step_size=7,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50에는 10개의 레이어가 있음. 입력에 가까운 0-5번 레이어까지 freeze\n",
    "ct = 0\n",
    "for child in resnet.children():\n",
    "    ct += 1\n",
    "    if ct < 6:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "def train_resnet(model,criterion,optimizer,scheduler,num_epochs=25):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-------------------epoch {}-------------------'.format(epoch+1))\n",
    "        since = time.time()\n",
    "        for phase in ['train','validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "            for inputs,labels in dataloader[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #_ 는 최댓값, preds는 최댓값의 위치 인덱스\n",
    "                    _, preds = torch.max(outputs,1) #torch.max(텐서, 찾으려는 최댓값을 가진 차원(0 = 열, 1 = 행)). \n",
    "                    loss = criterion(outputs,labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0) #미니배치에서의 손실이니, 미니배치의 크기를 곱하여 전체 손실의 계산\n",
    "                running_correct += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss/dataset_sizes[phase]\n",
    "            epoch_acc = running_correct.double()/dataset_sizes[phase] #정확도 계산에 필요한 타입 변환(Type Casting)을 수행 double()\n",
    "            print('{} Loss : {:.4f} Acc : {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "\n",
    "            if phase=='validation'and epoch_acc>best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60,time_elapsed % 60))\n",
    "    print('Best val ACC : {:.2f}',format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------epoch 1-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_resnet50 \u001b[39m=\u001b[39m train_resnet(resnet,criterion,optimizer_ft,exp_lr_shceduler,num_epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39msave(model_resnet50,\u001b[39m'\u001b[39m\u001b[39mresnet50.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 34\u001b[0m, in \u001b[0;36mtrain_resnet\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     33\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m         optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     36\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m#미니배치에서의 손실이니, 미니배치의 크기를 곱하여 전체 손실의 계산\u001b[39;00m\n\u001b[1;32m     37\u001b[0m running_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(preds \u001b[39m==\u001b[39m labels\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/adam.py:143\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    132\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    135\u001b[0m         group,\n\u001b[1;32m    136\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    141\u001b[0m         state_steps)\n\u001b[0;32m--> 143\u001b[0m     adam(\n\u001b[1;32m    144\u001b[0m         params_with_grad,\n\u001b[1;32m    145\u001b[0m         grads,\n\u001b[1;32m    146\u001b[0m         exp_avgs,\n\u001b[1;32m    147\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    148\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    149\u001b[0m         state_steps,\n\u001b[1;32m    150\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    151\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    152\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    153\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    160\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    161\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    162\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/adam.py:283\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 283\u001b[0m func(params,\n\u001b[1;32m    284\u001b[0m      grads,\n\u001b[1;32m    285\u001b[0m      exp_avgs,\n\u001b[1;32m    286\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    287\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    288\u001b[0m      state_steps,\n\u001b[1;32m    289\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    290\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    291\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    292\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    293\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    294\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    295\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    296\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    297\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    298\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    299\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_nightly/lib/python3.8/site-packages/torch/optim/adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    391\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    392\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    395\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_resnet50 = train_resnet(resnet,criterion,optimizer_ft,exp_lr_shceduler,num_epochs=epochs)\n",
    "torch.save(model_resnet50,'resnet50.pt')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
