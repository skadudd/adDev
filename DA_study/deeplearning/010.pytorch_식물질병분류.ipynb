{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이스라인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_device :  mps\n"
     ]
    }
   ],
   "source": [
    "is_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if is_mps else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('current_device : ',device)\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.mkdir('/Volumes/My Passport/dataset/data')\n",
    "# !unzip -qq '/Volumes/My Passport/dataset/dataset.zip' -d '/Volumes/My Passport/dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#폴더 이미 생성되어 주석처리\n",
    "original_dataset_dir = '/Volumes/My Passport/dataset/data'\n",
    "classes_list = []\n",
    "\n",
    "for i in os.listdir(original_dataset_dir):\n",
    "    if os.path.isdir(os.path.join(original_dataset_dir,i)):\n",
    "        classes_list.append(i)\n",
    "\n",
    "base_dir = '/Volumes/My Passport/dataset/splitted'\n",
    "# os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pepper,_bell___healthy\n",
      "Grape___Esca_(Black_Measles)\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Strawberry___healthy\n",
      "Grape___Black_rot\n",
      "Corn___Common_rust\n",
      "Apple___Apple_scab\n",
      "Potato___healthy\n",
      "Potato___Late_blight\n",
      "Cherry___healthy\n",
      "Tomato___Bacterial_spot\n",
      "Apple___Black_rot\n",
      "Cherry___Powdery_mildew\n",
      "Corn___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Peach___healthy\n",
      "Tomato___Early_blight\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Potato___Early_blight\n",
      "Grape___healthy\n",
      "Apple___Cedar_apple_rust\n",
      "Corn___Northern_Leaf_Blight\n",
      "Tomato___Septoria_leaf_spot\n",
      "Corn___healthy\n",
      "Strawberry___Leaf_scorch\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Late_blight\n",
      "Tomato___healthy\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Apple___healthy\n",
      "Tomato___Target_Spot\n",
      "Peach___Bacterial_spot\n"
     ]
    }
   ],
   "source": [
    "#데이터 분기할 폴더 트리 생성\n",
    "import shutil\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "# os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "# os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "# os.mkdir(test_dir)\n",
    "\n",
    "for cls in classes_list:\n",
    "    print(cls)\n",
    "    # os.mkdir(os.path.join(train_dir,cls))\n",
    "    # os.mkdir(os.path.join(validation_dir,cls))\n",
    "    # os.mkdir(os.path.join(test_dir,cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #데이터 현황 확인\n",
    "# #신규 트리구조로 파일 복사\n",
    "# import math\n",
    "\n",
    "# for cls in classes_list:\n",
    "#     if os.path.isdir(os.path.join(original_dataset_dir, cls)):\n",
    "#         path = os.path.join(original_dataset_dir,cls)\n",
    "#         #DS.store 파일 무시\n",
    "#         fnames = sorted((f for f in os.listdir(path) if not f.startswith('.')),key=str.lower)\n",
    "#         print(len(fnames))\n",
    "#         train_size = math.floor(len(fnames) * 0.6)\n",
    "#         validation_size = math.floor(len(fnames) * 0.2)\n",
    "#         test_size = math.floor(len(fnames) * 0.2)\n",
    "        \n",
    "#         train_fnames = fnames[:train_size]\n",
    "#         print(\"Train size(\",cls,\") \", len(train_fnames))\n",
    "#         for fname in train_fnames:\n",
    "#             source = os.path.join(path,fname)\n",
    "#             destination = os.path.join(os.path.join(train_dir,cls),fname)\n",
    "#             shutil.copyfile(source,destination)\n",
    "        \n",
    "#         validation_fnames = fnames[train_size:(train_size+validation_size)]\n",
    "#         print(\"Validation size(\",cls,\") \", len(validation_fnames))\n",
    "#         for fname in validation_fnames:\n",
    "#             source = os.path.join(path,fname)\n",
    "#             destination = os.path.join(os.path.join(validation_dir,cls),fname)\n",
    "#             shutil.copyfile(source,destination)\n",
    "        \n",
    "#         test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "#         print(\"Test size(\",cls,\") \", len(test_fnames))\n",
    "#         for fname in test_fnames:\n",
    "#             source = os.path.join(path,fname)\n",
    "#             destination = os.path.join(os.path.join(test_dir,cls),fname)\n",
    "#             shutil.copyfile(source,destination)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsfile 삭제\n",
    "folders = [train_dir,validation_dir,test_dir]\n",
    "\n",
    "for folder in folders:\n",
    "    for cls in classes_list:\n",
    "        target = folder+'/'+cls\n",
    "        for root, dirs, files in os.walk(target):\n",
    "            for file in files:\n",
    "                if file.startswith('.'):\n",
    "                    os.remove(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#이미지 사이즈 조정 및 텐서화\n",
    "transform_base = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])\n",
    "#이미지폴더 : 폴더를 클래스화. 폴더 이름을 라벨로 지정\n",
    "train_dataset = ImageFolder(root=train_dir,transform=transform_base)\n",
    "validation_dataset = ImageFolder(root=validation_dir,transform=transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4\n",
    "                          )\n",
    "val_loader = DataLoader(validation_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64,64,3,padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4096,512)\n",
    "        self.fc2 = nn.Linear(512,33)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x,p=0.25,training=self.training)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Net().to(device)\n",
    "optimizer = optim.Adam(model_base.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data,target = data.to(device),target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target,reduction='sum').sum()\n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct/len(test_loader.dataset)\n",
    "    return test_loss,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs=30):\n",
    "    best_acc = 0.0\n",
    "    best_model_weight = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        since = time.time()\n",
    "        train(model, train_loader,optimizer)\n",
    "        train_loss,train_acc = evaluate(model,train_loader)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_weight = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "        print('------------- epoch {} -------------'.format(epoch))\n",
    "        print('train loss:{:.4f}, Accuracy:{:.2f}%'.format(train_loss,train_acc))\n",
    "        print('val loss:{:.4f}, Accuracy:{:.2f}%'.format(val_loss,val_acc))\n",
    "        print('completed {:.0f}m {:.0f}s'.format(time_elapsed//60,time_elapsed%60))\n",
    "    \n",
    "    model.load_state_dict(best_model_weight)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론을 위해 모델을 저장할 때는 그 모델의 학습된 매개변수만 저장하면 됩니다. torch.save() 를 사용하여 모델의 state_dict 를 저장하는 것이 나중에 모델을 사용할 때 가장 유연하게 사용할 수 있는, 모델 저장 시 권장하는 방법입니다.\n",
    "\n",
    "PyTorch에서는 모델을 저장할 때 .pt 또는 .pth 확장자를 사용하는 것이 일반적인 규칙입니다.\n",
    "\n",
    "추론을 실행하기 전에 반드시 model.eval() 을 호출하여 드롭아웃 및 배치 정규화를 평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는 추론 결과가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch 1 -------------\n",
      "train loss:0.8813, Accuracy:74.68%\n",
      "val loss:0.9231, Accuracy:73.34%\n",
      "completed 2m 20s\n",
      "------------- epoch 2 -------------\n",
      "train loss:0.6885, Accuracy:77.99%\n",
      "val loss:0.7428, Accuracy:76.76%\n",
      "completed 2m 18s\n",
      "------------- epoch 3 -------------\n",
      "train loss:0.4274, Accuracy:87.40%\n",
      "val loss:0.4882, Accuracy:85.12%\n",
      "completed 2m 19s\n",
      "------------- epoch 4 -------------\n",
      "train loss:0.3710, Accuracy:88.02%\n",
      "val loss:0.4549, Accuracy:85.35%\n",
      "completed 2m 18s\n",
      "------------- epoch 5 -------------\n",
      "train loss:0.3495, Accuracy:88.63%\n",
      "val loss:0.4453, Accuracy:85.22%\n",
      "completed 2m 17s\n",
      "------------- epoch 6 -------------\n",
      "train loss:0.2308, Accuracy:93.18%\n",
      "val loss:0.3342, Accuracy:89.40%\n",
      "completed 18m 53s\n",
      "------------- epoch 7 -------------\n",
      "train loss:0.2068, Accuracy:93.84%\n",
      "val loss:0.3243, Accuracy:89.47%\n",
      "completed 10m 4s\n",
      "------------- epoch 8 -------------\n",
      "train loss:0.1604, Accuracy:95.11%\n",
      "val loss:0.2802, Accuracy:90.93%\n",
      "completed 21m 9s\n",
      "------------- epoch 9 -------------\n",
      "train loss:0.1497, Accuracy:95.57%\n",
      "val loss:0.2756, Accuracy:91.50%\n",
      "completed 2m 17s\n",
      "------------- epoch 10 -------------\n",
      "train loss:0.1373, Accuracy:95.78%\n",
      "val loss:0.2688, Accuracy:91.09%\n",
      "completed 2m 17s\n",
      "------------- epoch 11 -------------\n",
      "train loss:0.0999, Accuracy:97.07%\n",
      "val loss:0.2335, Accuracy:92.41%\n",
      "completed 2m 18s\n",
      "------------- epoch 12 -------------\n",
      "train loss:0.0970, Accuracy:97.40%\n",
      "val loss:0.2255, Accuracy:92.70%\n",
      "completed 2m 18s\n",
      "------------- epoch 13 -------------\n",
      "train loss:0.0928, Accuracy:97.17%\n",
      "val loss:0.2411, Accuracy:92.36%\n",
      "completed 2m 19s\n",
      "------------- epoch 14 -------------\n",
      "train loss:0.1116, Accuracy:96.46%\n",
      "val loss:0.2661, Accuracy:91.55%\n",
      "completed 2m 19s\n",
      "------------- epoch 15 -------------\n",
      "train loss:0.0820, Accuracy:97.47%\n",
      "val loss:0.2291, Accuracy:92.78%\n",
      "completed 2m 18s\n",
      "------------- epoch 16 -------------\n",
      "train loss:0.0696, Accuracy:98.06%\n",
      "val loss:0.2140, Accuracy:93.45%\n",
      "completed 2m 18s\n",
      "------------- epoch 17 -------------\n",
      "train loss:0.0922, Accuracy:97.31%\n",
      "val loss:0.2509, Accuracy:92.08%\n",
      "completed 2m 17s\n",
      "------------- epoch 18 -------------\n",
      "train loss:0.1026, Accuracy:96.71%\n",
      "val loss:0.2702, Accuracy:91.68%\n",
      "completed 2m 17s\n",
      "------------- epoch 19 -------------\n",
      "train loss:0.0675, Accuracy:97.86%\n",
      "val loss:0.2352, Accuracy:92.60%\n",
      "completed 2m 17s\n",
      "------------- epoch 20 -------------\n",
      "train loss:0.0594, Accuracy:98.16%\n",
      "val loss:0.2176, Accuracy:93.30%\n",
      "completed 2m 18s\n",
      "------------- epoch 21 -------------\n",
      "train loss:0.0452, Accuracy:98.94%\n",
      "val loss:0.1845, Accuracy:94.00%\n",
      "completed 2m 18s\n",
      "------------- epoch 22 -------------\n",
      "train loss:0.1037, Accuracy:96.50%\n",
      "val loss:0.2984, Accuracy:90.89%\n",
      "completed 2m 18s\n",
      "------------- epoch 23 -------------\n",
      "train loss:0.0674, Accuracy:97.67%\n",
      "val loss:0.2564, Accuracy:92.56%\n",
      "completed 2m 19s\n",
      "------------- epoch 24 -------------\n",
      "train loss:0.0541, Accuracy:98.44%\n",
      "val loss:0.2135, Accuracy:93.40%\n",
      "completed 2m 18s\n",
      "------------- epoch 25 -------------\n",
      "train loss:0.0439, Accuracy:98.67%\n",
      "val loss:0.2176, Accuracy:93.67%\n",
      "completed 2m 18s\n",
      "------------- epoch 26 -------------\n",
      "train loss:0.0417, Accuracy:98.79%\n",
      "val loss:0.2018, Accuracy:93.77%\n",
      "completed 2m 17s\n",
      "------------- epoch 27 -------------\n",
      "train loss:0.0485, Accuracy:98.51%\n",
      "val loss:0.2230, Accuracy:93.24%\n",
      "completed 2m 17s\n",
      "------------- epoch 28 -------------\n",
      "train loss:0.0441, Accuracy:98.61%\n",
      "val loss:0.2283, Accuracy:93.07%\n",
      "completed 2m 17s\n",
      "------------- epoch 29 -------------\n",
      "train loss:0.0206, Accuracy:99.60%\n",
      "val loss:0.1726, Accuracy:94.93%\n",
      "completed 2m 17s\n",
      "------------- epoch 30 -------------\n",
      "train loss:0.0345, Accuracy:99.00%\n",
      "val loss:0.1993, Accuracy:93.90%\n",
      "completed 2m 17s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base = train_baseline(model_base,train_loader,val_loader,optimizer,epochs)\n",
    "torch.save(base,'badseline.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전이학습 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train' : transforms.Compose([transforms.Resize([64,64]),\n",
    "        transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),\n",
    "        \n",
    "                                  ])\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
