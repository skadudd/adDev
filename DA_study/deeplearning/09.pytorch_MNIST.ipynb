{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.dev20230426\n",
      "True\n",
      "True\n",
      "Current device :  mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_built())\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "is_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if is_mps else 'cpu')\n",
    "print('Current device : ',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "learning_rate = 0.0001\n",
    "epoch_num = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Volumes/My Passport/dataset/MNIST/raw/train-images-idx3-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Volumes/My Passport/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Volumes/My Passport/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Volumes/My Passport/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Volumes/My Passport/dataset/MNIST/raw\n",
      "\n",
      "number of training data:  60000\n",
      "number of test data:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = '/Volumes/My Passport/dataset',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = '/Volumes/My Passport/dataset',\n",
    "                           train=False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "print('number of training data: ',len(train_data))\n",
    "print('number of test data: ',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label:5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "#tensorflow 와 다르게 차원 축이 맨 앞에 위치한다. squeeze는 1인 차원을 삭제함\n",
    "print(image.shape)\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "plt.title(f'label:{label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#미니배치 구성\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data,batch_size = batch_size, shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of Batch    |                           | 1200\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "#print 간격 설정\n",
    "#first_batch의 픽셀값, 라벨값\n",
    "print('{:15s} | {:<25s} | {}'.format('name','type','size'))\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of Batch','',len(train_loader)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch',str(type(first_batch)),len(first_batch)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[0]',str(type(first_batch[0])),first_batch[0].shape))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[1]',str(type(first_batch[1])),first_batch[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #Conv2(입력채널의 수(들어오는 데이터 양), 출력채널, 커널 사이즈(3x3), stride(1x1))\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1,padding='same')\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1,padding='same')\n",
    "        self.dropout = nn.Dropout2d(0.25)\n",
    "        #이미지 해상도 = 28x28, 맥스풀링 2x2로 설정. 풀링 2번 거치며 7x7로 작아짐. 바로 앞 채널과 곱한 크기를 선형계층에 전달\n",
    "        self.fc1 = nn.Linear(3136,1000)#*7*64\n",
    "        self.fc2 = nn.Linear(1000,10)#최종 아웃풋 갯수\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #'dim=1'은 log_softmax 함수의 적용 대상인 차원을 지정하는 매개변수. \n",
    "        #텐서의 크기가 (batch_size, num_classes)라면, dim=1을 지정하면 두 번째 차원(즉, num_classes에 해당하는 차원)에 대해서 log_softmax 함수를 적용하게 됩\n",
    "        output = F.log_softmax(x,dim=1) #log_softmax가 속도가 빠름. \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) #모델을 인스턴시에이션 시킨 후, 디바이스에 올려라.\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step : 100\tLoss : 0.7151188850402832\n",
      "Train step : 200\tLoss : 0.5080346465110779\n",
      "Train step : 300\tLoss : 0.28048470616340637\n",
      "Train step : 400\tLoss : 0.30649125576019287\n",
      "Train step : 500\tLoss : 0.18425580859184265\n",
      "Train step : 600\tLoss : 0.23009946942329407\n",
      "Train step : 700\tLoss : 0.16801254451274872\n",
      "Train step : 800\tLoss : 0.12933844327926636\n",
      "Train step : 900\tLoss : 0.19969375431537628\n",
      "Train step : 1000\tLoss : 0.0414033941924572\n",
      "Train step : 1100\tLoss : 0.16367992758750916\n",
      "Train step : 1200\tLoss : 0.04470966383814812\n",
      "Train step : 1300\tLoss : 0.050514914095401764\n",
      "Train step : 1400\tLoss : 0.04395879805088043\n",
      "Train step : 1500\tLoss : 0.14772985875606537\n",
      "Train step : 1600\tLoss : 0.18032032251358032\n",
      "Train step : 1700\tLoss : 0.1957457959651947\n",
      "Train step : 1800\tLoss : 0.1216491311788559\n",
      "Train step : 1900\tLoss : 0.1265714317560196\n",
      "Train step : 2000\tLoss : 0.08575296401977539\n",
      "Train step : 2100\tLoss : 0.06768563389778137\n",
      "Train step : 2200\tLoss : 0.1616283357143402\n",
      "Train step : 2300\tLoss : 0.02400648035109043\n",
      "Train step : 2400\tLoss : 0.05724252760410309\n",
      "Train step : 2500\tLoss : 0.018522869795560837\n",
      "Train step : 2600\tLoss : 0.10553492605686188\n",
      "Train step : 2700\tLoss : 0.07162944972515106\n",
      "Train step : 2800\tLoss : 0.0756848081946373\n",
      "Train step : 2900\tLoss : 0.08906310796737671\n",
      "Train step : 3000\tLoss : 0.15549100935459137\n",
      "Train step : 3100\tLoss : 0.00918586552143097\n",
      "Train step : 3200\tLoss : 0.11432701349258423\n",
      "Train step : 3300\tLoss : 0.025142712518572807\n",
      "Train step : 3400\tLoss : 0.06678856164216995\n",
      "Train step : 3500\tLoss : 0.055787593126297\n",
      "Train step : 3600\tLoss : 0.05716770514845848\n",
      "Train step : 3700\tLoss : 0.032037876546382904\n",
      "Train step : 3800\tLoss : 0.0115605928003788\n",
      "Train step : 3900\tLoss : 0.06626264750957489\n",
      "Train step : 4000\tLoss : 0.025028442963957787\n",
      "Train step : 4100\tLoss : 0.1469130665063858\n",
      "Train step : 4200\tLoss : 0.10503541678190231\n",
      "Train step : 4300\tLoss : 0.10292833298444748\n",
      "Train step : 4400\tLoss : 0.06405679881572723\n",
      "Train step : 4500\tLoss : 0.024781756103038788\n",
      "Train step : 4600\tLoss : 0.037508275359869\n",
      "Train step : 4700\tLoss : 0.009757660329341888\n",
      "Train step : 4800\tLoss : 0.019983375445008278\n",
      "Train step : 4900\tLoss : 0.002951623871922493\n",
      "Train step : 5000\tLoss : 0.11764202266931534\n",
      "Train step : 5100\tLoss : 0.007329423446208239\n",
      "Train step : 5200\tLoss : 0.02072381228208542\n",
      "Train step : 5300\tLoss : 0.05839468538761139\n",
      "Train step : 5400\tLoss : 0.023155055940151215\n",
      "Train step : 5500\tLoss : 0.0050795613788068295\n",
      "Train step : 5600\tLoss : 0.04246921464800835\n",
      "Train step : 5700\tLoss : 0.10628962516784668\n",
      "Train step : 5800\tLoss : 0.017814481630921364\n",
      "Train step : 5900\tLoss : 0.13310740888118744\n",
      "Train step : 6000\tLoss : 0.018613899126648903\n",
      "Train step : 6100\tLoss : 0.018079586327075958\n",
      "Train step : 6200\tLoss : 0.00258910795673728\n",
      "Train step : 6300\tLoss : 0.0043028490617871284\n",
      "Train step : 6400\tLoss : 0.032273128628730774\n",
      "Train step : 6500\tLoss : 0.04394369199872017\n",
      "Train step : 6600\tLoss : 0.006534932646900415\n",
      "Train step : 6700\tLoss : 0.007456194143742323\n",
      "Train step : 6800\tLoss : 0.1409057378768921\n",
      "Train step : 6900\tLoss : 0.013358308002352715\n",
      "Train step : 7000\tLoss : 0.06022180989384651\n",
      "Train step : 7100\tLoss : 0.002193760359659791\n",
      "Train step : 7200\tLoss : 0.0017348225228488445\n",
      "Train step : 7300\tLoss : 0.10234764963388443\n",
      "Train step : 7400\tLoss : 0.019813580438494682\n",
      "Train step : 7500\tLoss : 0.02936733514070511\n",
      "Train step : 7600\tLoss : 0.022636892274022102\n",
      "Train step : 7700\tLoss : 0.013988234102725983\n",
      "Train step : 7800\tLoss : 0.016608359292149544\n",
      "Train step : 7900\tLoss : 0.05315758287906647\n",
      "Train step : 8000\tLoss : 0.03448458015918732\n",
      "Train step : 8100\tLoss : 0.1417653113603592\n",
      "Train step : 8200\tLoss : 0.030650965869426727\n",
      "Train step : 8300\tLoss : 0.044829778373241425\n",
      "Train step : 8400\tLoss : 0.01912599243223667\n",
      "Train step : 8500\tLoss : 0.011593937873840332\n",
      "Train step : 8600\tLoss : 0.008763969875872135\n",
      "Train step : 8700\tLoss : 0.019162338227033615\n",
      "Train step : 8800\tLoss : 0.013695502653717995\n",
      "Train step : 8900\tLoss : 0.05356130748987198\n",
      "Train step : 9000\tLoss : 0.00524970842525363\n",
      "Train step : 9100\tLoss : 0.012253399938344955\n",
      "Train step : 9200\tLoss : 0.007760879583656788\n",
      "Train step : 9300\tLoss : 0.003995145205408335\n",
      "Train step : 9400\tLoss : 0.015282686799764633\n",
      "Train step : 9500\tLoss : 0.003794480348005891\n",
      "Train step : 9600\tLoss : 0.06406953930854797\n",
      "Train step : 9700\tLoss : 0.008495841175317764\n",
      "Train step : 9800\tLoss : 0.00802621804177761\n",
      "Train step : 9900\tLoss : 0.028496623039245605\n",
      "Train step : 10000\tLoss : 0.08751779794692993\n",
      "Train step : 10100\tLoss : 0.0075409067794680595\n",
      "Train step : 10200\tLoss : 0.037064991891384125\n",
      "Train step : 10300\tLoss : 0.12604612112045288\n",
      "Train step : 10400\tLoss : 0.0024873344227671623\n",
      "Train step : 10500\tLoss : 0.05669553205370903\n",
      "Train step : 10600\tLoss : 0.004361054394394159\n",
      "Train step : 10700\tLoss : 0.032118335366249084\n",
      "Train step : 10800\tLoss : 0.004690790548920631\n",
      "Train step : 10900\tLoss : 0.009090355597436428\n",
      "Train step : 11000\tLoss : 0.01665075123310089\n",
      "Train step : 11100\tLoss : 0.041902586817741394\n",
      "Train step : 11200\tLoss : 0.01783987134695053\n",
      "Train step : 11300\tLoss : 0.003226509317755699\n",
      "Train step : 11400\tLoss : 0.0402076430618763\n",
      "Train step : 11500\tLoss : 0.012417308986186981\n",
      "Train step : 11600\tLoss : 0.0846894234418869\n",
      "Train step : 11700\tLoss : 0.014571993611752987\n",
      "Train step : 11800\tLoss : 0.0009078354923985898\n",
      "Train step : 11900\tLoss : 0.043639011681079865\n",
      "Train step : 12000\tLoss : 0.051016394048929214\n",
      "Train step : 12100\tLoss : 0.0036292069125920534\n",
      "Train step : 12200\tLoss : 0.0007845048094168305\n",
      "Train step : 12300\tLoss : 0.0690317451953888\n",
      "Train step : 12400\tLoss : 0.004643267020583153\n",
      "Train step : 12500\tLoss : 0.0037340614944696426\n",
      "Train step : 12600\tLoss : 0.0417303740978241\n",
      "Train step : 12700\tLoss : 0.005871936213225126\n",
      "Train step : 12800\tLoss : 0.0012209119740873575\n",
      "Train step : 12900\tLoss : 0.0018692744197323918\n",
      "Train step : 13000\tLoss : 0.043321143835783005\n",
      "Train step : 13100\tLoss : 0.0009686717530712485\n",
      "Train step : 13200\tLoss : 0.0028878108132630587\n",
      "Train step : 13300\tLoss : 0.009216954931616783\n",
      "Train step : 13400\tLoss : 0.02686523273587227\n",
      "Train step : 13500\tLoss : 0.0019445589277893305\n",
      "Train step : 13600\tLoss : 0.0029534646309912205\n",
      "Train step : 13700\tLoss : 0.012933213263750076\n",
      "Train step : 13800\tLoss : 0.0073301466181874275\n",
      "Train step : 13900\tLoss : 0.001206711633130908\n",
      "Train step : 14000\tLoss : 0.06684380769729614\n",
      "Train step : 14100\tLoss : 0.009567378088831902\n",
      "Train step : 14200\tLoss : 0.0020301558542996645\n",
      "Train step : 14300\tLoss : 0.008839627727866173\n",
      "Train step : 14400\tLoss : 0.01537609938532114\n",
      "Train step : 14500\tLoss : 0.0026010104920715094\n",
      "Train step : 14600\tLoss : 0.0006569386459887028\n",
      "Train step : 14700\tLoss : 0.001279104850254953\n",
      "Train step : 14800\tLoss : 0.009210366755723953\n",
      "Train step : 14900\tLoss : 0.020838774740695953\n",
      "Train step : 15000\tLoss : 0.02027244307100773\n",
      "Train step : 15100\tLoss : 0.07972131669521332\n",
      "Train step : 15200\tLoss : 0.0045968955382704735\n",
      "Train step : 15300\tLoss : 0.02070627734065056\n",
      "Train step : 15400\tLoss : 0.06100885570049286\n",
      "Train step : 15500\tLoss : 0.02182944305241108\n",
      "Train step : 15600\tLoss : 0.029743818566203117\n",
      "Train step : 15700\tLoss : 0.005852903705090284\n",
      "Train step : 15800\tLoss : 0.0014262167969718575\n",
      "Train step : 15900\tLoss : 0.00842074491083622\n",
      "Train step : 16000\tLoss : 0.0039988113567233086\n",
      "Train step : 16100\tLoss : 0.00029104246641509235\n",
      "Train step : 16200\tLoss : 0.001832102658227086\n",
      "Train step : 16300\tLoss : 0.015982283279299736\n",
      "Train step : 16400\tLoss : 0.002321516629308462\n",
      "Train step : 16500\tLoss : 0.007663200609385967\n",
      "Train step : 16600\tLoss : 0.0013187940930947661\n",
      "Train step : 16700\tLoss : 0.006345681380480528\n",
      "Train step : 16800\tLoss : 0.016934834420681\n",
      "Train step : 16900\tLoss : 0.0011437565553933382\n",
      "Train step : 17000\tLoss : 0.0018371948972344398\n",
      "Train step : 17100\tLoss : 0.009032782167196274\n",
      "Train step : 17200\tLoss : 0.002374569419771433\n",
      "Train step : 17300\tLoss : 0.012175345793366432\n",
      "Train step : 17400\tLoss : 0.0010376774007454515\n",
      "Train step : 17500\tLoss : 0.00021996322902850807\n",
      "Train step : 17600\tLoss : 0.008106568828225136\n",
      "Train step : 17700\tLoss : 0.004871334880590439\n",
      "Train step : 17800\tLoss : 0.00016254876391030848\n",
      "Train step : 17900\tLoss : 0.10160952806472778\n",
      "Train step : 18000\tLoss : 0.0014597702538594604\n"
     ]
    }
   ],
   "source": [
    "model.train() #훈련할 거라고 선언하는 것.\n",
    "i=1\n",
    "for epoch in range(epoch_num): #epoch loop\n",
    "    for data,target in train_loader: #batch loop\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('Train step : {}\\tLoss : {}'.format(i,loss.item()))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set : Accuracy:99.17%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1] #2차원 텐서에서 클래스레이블 형태로 추출 (가장 큰 값의 인덱스)\n",
    "    correct += prediction.eq(target.data).sum() #예측값과 타겟값이 같은지\n",
    "\n",
    "print('Test set : Accuracy:{:.2f}%'.format(100. * correct/len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
